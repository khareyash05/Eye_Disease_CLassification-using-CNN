{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='D:/Datasets/Image dataset/eye disease/eye-disease-dataset/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of images to feed in neural network\n",
    "image_shape = (100,100,3) \n",
    "#data augmentation\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=30, # rotate the image 30 degrees\n",
    "                               width_shift_range=0.1, # Shift the pic width by a max of 10%\n",
    "                               height_shift_range=0.1, # Shift the pic height by a max of 10%\n",
    "                               rescale=1/255, # Rescale the image by normalzing it.\n",
    "                               shear_range=0.2, # Shear means cutting away part of the image (max 20%)\n",
    "                               zoom_range=0.2, # Zoom in by 20% max\n",
    "                               horizontal_flip=True, # Allo horizontal flipping\n",
    "                               vertical_flip=True,\n",
    "                               fill_mode='nearest',# Fill in missing pixels with the nearest filled value\n",
    "                               validation_split=0.2#split data to train and test\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 726 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#load the training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path+'Cropped_Images/',\n",
    "    target_size=image_shape[0:2],\n",
    "    batch_size=100,\n",
    "    class_mode='categorical',\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#load the test data\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    path+'Cropped_Images/',\n",
    "    target_size=image_shape[0:2],\n",
    "    batch_size=100,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 3,input_shape=image_shape,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters = 32,kernel_size = 3,activation= 'relu',padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters = 64,kernel_size = 3,activation= 'relu',padding='same'))\n",
    "#model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters = 64,kernel_size = 5,activation= 'relu',padding='valid'))\n",
    "model.add(Conv2D(filters = 128,kernel_size = 3,activation= 'relu',padding='valid'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5,activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 100, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 100, 100, 32)      4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 96, 96, 64)        102464    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 94, 94, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 282752)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               36192384  \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 36,400,869\n",
      "Trainable params: 36,400,869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create class weights for unbalance dataset\n",
    "from sklearn.utils import class_weight\n",
    "y_train=train_generator.classes\n",
    "class_weights = class_weight.compute_class_weight('balanced',np.unique(y_train),y_train)\n",
    "class_weights=dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=keras.callbacks.EarlyStopping(monitor='val_acc',mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 61s 2s/step - loss: 1.6302 - acc: 0.1718 - val_loss: 1.5973 - val_acc: 0.2237\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.5490 - acc: 0.2809 - val_loss: 1.5536 - val_acc: 0.2330\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 55s 2s/step - loss: 1.5052 - acc: 0.3094 - val_loss: 1.4780 - val_acc: 0.2911\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 55s 2s/step - loss: 1.4466 - acc: 0.3404 - val_loss: 1.5059 - val_acc: 0.3226\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.4150 - acc: 0.3637 - val_loss: 1.4585 - val_acc: 0.3911\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.3437 - acc: 0.3977 - val_loss: 1.5270 - val_acc: 0.3485\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.2772 - acc: 0.4076 - val_loss: 1.5433 - val_acc: 0.3485\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 57s 2s/step - loss: 1.2239 - acc: 0.4554 - val_loss: 1.3789 - val_acc: 0.4185\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 58s 2s/step - loss: 1.1381 - acc: 0.5122 - val_loss: 1.3509 - val_acc: 0.4526\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 59s 2s/step - loss: 1.1405 - acc: 0.4937 - val_loss: 1.3517 - val_acc: 0.4181\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "results = model.fit_generator(train_generator,epochs=10,\n",
    "                              steps_per_epoch=30,\n",
    "                              validation_data=test_generator,\n",
    "                             validation_steps=30,\n",
    "                              #callbacks=[es],\n",
    "                             class_weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "Bulging_Eyes       0.28      0.26      0.27        43\n",
      "   Cataracts       0.04      0.09      0.06        11\n",
      "Crossed_Eyes       0.55      0.33      0.41        88\n",
      "    Glaucoma       0.15      0.23      0.18        22\n",
      "     Uveitis       0.10      0.19      0.13        16\n",
      "\n",
      "    accuracy                           0.27       180\n",
      "   macro avg       0.22      0.22      0.21       180\n",
      "weighted avg       0.36      0.27      0.30       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print classification report\n",
    "y_true=test_generator.classes\n",
    "class_label=list(train_generator.class_indices.keys())\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model.predict_generator(test_generator,steps=186/100) #186 are total example in test set and 40 is batch size\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(classification_report(y_true, y_pred,target_names=class_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
